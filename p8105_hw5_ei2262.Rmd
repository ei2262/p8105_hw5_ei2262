---
title: "Homework 5"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(broom)
```

# Problem 1 Attempt

```{r, eval = FALSE}
list.files(path="./data", pattern=NULL, all.files=FALSE,
    full.names=FALSE)
```

# Problem 1 Solution

The code chunk below imports the data in individual spreadsheets contained in `./data/zip_data/`. To do this, I create a dataframe that includes the list of all files in that directory and the complete path to each file. As a next step, I `map` over paths and import data using the `read_csv` function. Finally, I `unnest` the result of `map`.

```{r, eval = FALSE}
full_df = 
  tibble(
    files = list.files("data/zip_data/"),
    path = str_c("data/zip_data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest()
```

The result of the previous code chunk isn't tidy -- data are wide rather than long, and some important variables are included as parts of others. The code chunk below tides the data using string manipulations on the file, converting from wide to long, and selecting relevant variables. 

```{r, eval = FALSE}
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```

Finally, the code chunk below creates a plot showing individual data, faceted by group. 

```{r, eval = FALSE}
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

This plot suggests high within-subject correlation -- subjects who start above average end up above average, and those that start below average end up below average. Subjects in the control group generally don't change over time, but those in the experiment group increase their outcome in a roughly linear way. 

# Problem 2

### Raw Dataset

```{r}
urlfile="https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

post_homicide = read_csv(url(urlfile))
```
The raw dataset `post_homicide` includes `r ncol(post_homicide)` columns and `r nrow(post_homicide)` rows. The columns include reported date of homicide, location of the killing, whether an arrest was made or not, and basic demographics about each victim. Demographic information collected include the victims name, age, race, and sex. Information collected about the location of the killing include the city, state, and geographic coordinates (longitudinal and latitudinal coordinates).

#### Creating `city_state` variable and summarizing total number of homicides and unsolved homicides
```{r}
post_homicide =
  post_homicide %>% 
  mutate(city_state = paste(city, state, sep=", "))

total_homicides = post_homicide %>% 
  group_by(city_state) %>% 
  summarize(
        total_homicides = n())

unsolved_homicides = post_homicide %>% 
  group_by(city_state) %>% 
  filter(disposition %in% c("Closed without arrest", "Open/No arrest")) %>% 
  summarize(
    unsolved_homicides = n())

output = merge(total_homicides,unsolved_homicides,by=c("city_state"))
knitr::kable(output, col.names = c("City, State", "Total Homicides", "Unsolved Homicides"))
```

#### `prop.test` of Baltimore,MD
```{r}
baltimore_post = 
  prop.test(x=1825, n=2827, p = NULL, alternative = "two.sided", conf.level = 0.95, correct = TRUE) %>% 
  tidy() %>% 
  select(estimate, conf.low, conf.high)

knitr::kable(baltimore_post, digits = 3)
```

#### `prop.test` for each city in the dataset
```{r}
each_city = output %>% 
  mutate(
    result = map2(output$unsolved_homicides, output$total_homicides, prop.test),
    result = map(result, tidy),
    result = map(result, ~select(.x, estimate, conf.low, conf.high))) %>% 
  unnest(cols = c(result))

knitr::kable(each_city, digits = 3)
```

#### Plot that shows the estimates and CIs for each city
```{r}
each_city %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate, color = city_state)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.4) +
  theme(legend.position = "none", axis.text.x = element_text(angle = 90)) +
  labs(
    title = "Proportion of Unsolved Homicides in The U.S.",
    x = "City, State",
    y = "Estimated Proportions"
  )

```

# Problem 3

#### Generating 5000 datasets with fixed design elements (n=30, sigma = 5, mu = 0) and running `t.test`
```{r}
set.seed(1)

new_datasets = map(1:5000, ~ rnorm(n = 30, mean = 0, sd = 5))

ttest_datasets = 
  map(new_datasets, t.test) %>% 
  map(tidy) %>% 
  map(~select(.x, estimate, p.value)) %>%
  as.data.frame() %>%
  pivot_longer(cols = everything(),
               names_to = "parameter",
               values_to = "values") 
    
ttest_datasets[2, "parameter"] <- "p.value.0"
ttest_datasets[1, "parameter"] <- "estimate.0"

ttest_datasets
```

#### Generating 5000 datasets with fixed design elements (n=30, sigma = 5) and multiple mu values

```{r}
set.seed(2)

multi_datasets = 
  tibble(mu = c(1,2,3,4,5,6)) %>% 
  mutate(
    output_lists = map(.x = mu, ~rerun(5000, rnorm(n=30, mean = .x, sd = 5)))) %>%
  unnest(output_lists)

multi_dataset = multi_datasets %>% 
  pull(output_lists) %>% 
  lapply(t.test) %>% 
  map(tidy) %>%
  map(~select(.x, estimate, p.value)) %>% 
  as.data.frame() %>%
  pivot_longer(cols = everything(),
               names_to = "parameter",
               values_to = "values") 
multi_dataset[2, "parameter"] <- "p.value.0"
multi_dataset[1, "parameter"] <- "estimate.0"

multi_dataset["mu"] = rep(c(1,2,3,4,5,6),each=10000)
```

##### Plot 1: Proportion of times the null was rejected

```{r}
multi_plotone = multi_dataset %>% 
  mutate(parameter = sub("\\..*[0-9999]", "", parameter),
         parameter = recode(parameter, p = "p_value")) %>% 
  filter(grepl("^p", parameter)) %>% 
  filter(values < 0.05) %>% 
  add_count(mu,parameter) %>% 
  ggplot(aes(x = mu)) +
  geom_bar(fill="lightblue") +
  labs(title = "Figure 1: Proportion of times null was rejected vs. true value of mean",
       x = "true mean value", 
       y = "proportion of times null was rejected") +
  scale_x_discrete(limits=c("1","2","3","4","5","6")) + ylim(0,5250) + stat_count(geom = "text", colour = "black", aes(label = ..count..))

multi_plotone
```

The association between effect size and power is that the effect size is the difference between 
the true value (in this case, true mean value) and the value specified in the null hypothesis (in this case, $\mu$ = 0). For this problem, we identified 5 different $\mu$ values, 1 to 6. Effect size affects power because the greater the difference between the true $\mu$ value and and value specified in the null hypothesis, the greater the power of the test. Simply put, a larger effect size yields greater power of the test. In our dataset, we would expect the proportion of times the null was rejected to increase as we increase in our $\mu$ value because the effect size becomes larger. Therefore, $\mu$=6 is expected to have the largest power, which is seen in the Figure 1. 

##### Plot 2: Average estimate of mu_hat 
```{r}
multi_plottwo = multi_dataset %>% 
  mutate(parameter = sub("\\..*[0-9999]", "", parameter),
         parameter = recode(parameter, p = "p_value")) %>% 
  filter(grepl("^e", parameter)) %>% 
  group_by(mu) %>% 
  nest() %>% 
  mutate(mean_mu = map_dbl(data, ~ mean(.x$values)))

multi_pvalue = multi_dataset %>% 
  mutate(parameter = sub("\\..*[0-9999]", "", parameter),
         parameter = recode(parameter, p = "p.value")) %>% 
  unite("parameters", parameter:values, remove = FALSE) %>% 
  filter(grepl("^p", parameter)) %>% 
  select(parameters, mu) %>% 
  separate(parameters, into = c('p_value', 'p_values'), sep = "_")

multi_estimate = multi_dataset %>% 
  mutate(parameter = sub("\\..*[0-9999]", "", parameter),
         parameter = recode(parameter, p = "p.value")) %>% 
  unite("parameters", parameter:values, remove = FALSE) %>% 
  filter(grepl("^e", parameter)) %>% 
  select(parameters) %>% 
  separate(parameters, into = c('estimate', 'values'), sep = "_") %>% 
  mutate(values = as.numeric(values))
           
overlay_plots =
  cbind(multi_estimate, multi_pvalue) %>% 
  filter(p_values <= 0.05) %>% 
  group_by(mu) %>% 
  nest() %>% 
  mutate(mean_mu = map_dbl(data, ~ mean(.x$values)))
  
overlay_plot = ggplot(multi_plottwo, aes(x=mu, y = mean_mu)) +
  geom_line() + 
  geom_line(data = overlay_plots, color = "red") +
  labs(title = "Figure 2: Average estimate of mu_hat compared to the true value of mu",
       x = "true mean value",
       y = "average mean value")
  
overlay_plot
```

The sample average of $\hat{\mu}$ across tests for which the null is rejected (*p-value ≤ 0.05*) is not approximately equal to the true value of $\mu$. In Figure 2, the black line represents the plot showing the average estimate of $\hat{\mu}$ vs. the true value of $\mu$. The red line represents the plot showing the average estimate of $\hat{\mu}$ **only** in samples for which the null was rejected . Figure 2 shows two lines that are not identical to one another. We can conclude that the two average estimates of $\hat{\mu}$ are not equivalent. One explanation may be that the sample average of $\hat{\mu}$ **only** in samples for which the null was rejected is larger to increase the effect size and ultimately reject the null hypothesis. The dataset that was restricted to p-values ≤ 0.05 and only values that have a larger mean estimate was left, which was then used to calculate the average estimate of $\hat{\mu}$. That is why the average estimate is much larger than the true value of $\mu$.
